# Default Azure AI settings with Docker
Esse projeto, tem como objetivo, desenvolver um ambiente padr√£o dentro de um container, docker, junto com os servicos da AI Azure para facilitar a criacao e os desenvolvimentos de IA's que irei realizar pela frente. Temos, como expectativa, em que esse projeto padr√£o, futuramente, sirva para outros servios de IA's de nuvem (AWS, Google GCP, etc...)

Para utilizar o **Docker** junto com o servi√ßo de **Azure AI** e construir um **container** com **NVIDIA CUDA** instalado, voc√™ pode seguir os passos abaixo. O objetivo √© criar um ambiente onde voc√™ possa verificar se a GPU dispon√≠vel no servi√ßo da Azure est√° funcionando corretamente.

---

## **1. Pr√©-requisitos**
Antes de come√ßar, certifique-se de que voc√™ tem:

1. **Conta no Azure** com acesso a um **VM com GPU** ou **Azure Machine Learning (AML)**.
2. **Instalado o Docker** na sua m√°quina local.
3. **Docker com suporte a NVIDIA**:
   - **NVIDIA Container Toolkit** instalado ([Guia de instala√ß√£o](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)).
   - Driver da GPU atualizado.
4. **Azure CLI** instalado e configurado.

---

## **2. Criando o Dockerfile com CUDA**
Vamos criar um Dockerfile que instala o **CUDA** e configura um ambiente b√°sico para testar a GPU.

Crie um arquivo chamado **`Dockerfile`**:

```dockerfile
# Usa a imagem oficial da NVIDIA com CUDA e cuDNN
FROM nvidia/cuda:12.2.2-devel-ubuntu22.04

# Instala pacotes necess√°rios
RUN apt-get update \
    && apt-get upgrade -y \
    && apt-get install --assume-yes --no-install-recommends \
    ca-certificates \
    build-essential \
    git \
    nano \
    curl \
    wget \
    gnupg2 \
    lsb-release \
    libssl-dev \
    zlib1g-dev \
    libbz2-dev \
    libreadline-dev \
    libsqlite3-dev \
    llvm \
    libncurses5-dev \
    libncursesw5-dev \
    xz-utils \
    tk-dev \
    libxml2-dev \
    libxmlsec1-dev \
    libffi-dev \
    liblzma-dev \
    python3-openssl \
    libopenblas-base \
    libopenblas-dev \
    logrotate \
    less \
    sudo \
    apt-utils \
    dpkg \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /opt

ENV PYENV_ROOT /opt/.pyenv
ENV PATH ${PYENV_ROOT}/bin:${PYENV_ROOT}/shims:${PATH}
ARG PYTHON_VERSION=3.10.15
RUN git clone https://github.com/pyenv/pyenv.git ${PYENV_ROOT} \
    && echo 'export PATH="${PYENV_ROOT}/bin:${PYENV_ROOT}/shims:${PATH}"' >> ~/.bashrc \
    && echo 'eval "$(pyenv init -)"' >> ~/.bashrc \
    && eval "$(pyenv init -)" \
    && source ~/.bashrc \
    && CFLAGS=-I/usr/include LDFLAGS=-L/usr/lib pyenv install -v ${PYTHON_VERSION} \
    && pyenv global ${PYTHON_VERSION} \
    && pyenv rehash \
    && python --version \
    && pip install --upgrade pip

# Instala pacotes Python para testar GPU
WORKDIR /azure-service-models

COPY . .

RUN apt-get update \
    && apt-get -y upgrade \
    && nvcc --version \
    && pip install -U -r requirements.txt \
    && pip freeze > requirements.txt

# Copia e executa um script de teste da GPU
CMD ["python", "test_gpu_pytorch.py"]
```

---

## **3. Criando o script Python para testar a GPU**
Crie um arquivo chamado **`test_gpu.py`** no mesmo diret√≥rio do Dockerfile:

```python
import torch

if torch.cuda.is_available():
    print("‚úÖ GPU dispon√≠vel!")
    print(f"Nome da GPU: {torch.cuda.get_device_name(0)}")
    print(f"Quantidade de GPUs dispon√≠veis: {torch.cuda.device_count()}")
    print(f"Mem√≥ria total da GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
else:
    print("‚ùå GPU n√£o detectada!")
```

---

## **4. Construindo e rodando o container**
Agora, vamos construir e executar o container **Docker**.

### **4.1. Utilizando Somente Imagem (Dockerfile)**
#### **4.1.1. Construindo a imagem Docker**
No terminal, execute:

```sh
docker build -t my_cuda_container .
```

Isso criar√° uma imagem chamada **my_cuda_container** com CUDA instalado.

#### **4.1.2. Executando o container com suporte √† GPU**
Se estiver em uma m√°quina com suporte √† GPU e **NVIDIA Container Toolkit** instalado, execute:

```sh
docker run --gpus all --rm my_cuda_container
```

Se a GPU for detectada corretamente, voc√™ ver√° uma sa√≠da semelhante a esta:

```
‚úÖ GPU dispon√≠vel!
Nome da GPU: NVIDIA A100-SXM4-40GB
Quantidade de GPUs dispon√≠veis: 1
Mem√≥ria total da GPU: 40.00 GB
```
### **4.2. Utilizando docker-compose.yml**

---

## **5. Subindo o container no Azure**
Se quiser rodar esse container em uma **VM do Azure com GPU**, siga os passos abaixo.

### **5.1. Criando uma VM com GPU no Azure**
1. Acesse o [Portal do Azure](https://portal.azure.com/).
2. V√° para **M√°quinas Virtuais** ‚ûù **Criar VM**.
3. Escolha um **tamanho compat√≠vel com GPU** (ex: `Standard_NC6`, `Standard_ND6s`, etc.).
4. No **sistema operacional**, escolha **Ubuntu 22.04 LTS**.
5. No **tamanho do disco**, escolha pelo menos **100GB SSD**.
6. Habilite a op√ß√£o **"Suporte a GPU"**.
7. Finalize a configura√ß√£o e inicie a VM.

### **5.2. Conectando-se √† VM**
Ap√≥s a VM estar criada, conecte-se via SSH:

```sh
ssh azure-user@<IP_DA_VM>
```

### **5.3. Instalando Docker e NVIDIA Container Toolkit**
Na VM do Azure, execute:

```sh
# Instalar Docker
sudo apt update
sudo apt install -y docker.io
sudo systemctl enable docker
sudo systemctl start docker

# Adicionar usu√°rio ao grupo docker
sudo usermod -aG docker $USER
newgrp docker

# Instalar NVIDIA Container Toolkit
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt update && sudo apt install -y nvidia-container-toolkit

# Reiniciar Docker para ativar suporte √† GPU
sudo systemctl restart docker
```

### **5.4. Transferindo e rodando o container na Azure VM**
Agora, copie os arquivos para a VM:

```sh
scp -r . azure-user@<IP_DA_VM>:~/cuda-test
```

Conecte-se √† VM e rode os comandos:

```sh
cd ~/cuda-test
docker build -t my_cuda_container .
docker run --gpus all --rm my_cuda_container
```

Se tudo estiver correto, voc√™ ver√° a sa√≠da confirmando que a GPU est√° dispon√≠vel.

---

## **Conclus√£o**
Agora voc√™ tem um **container Docker com NVIDIA CUDA** rodando em uma **VM do Azure com GPU**. Isso pode ser expandido para rodar modelos de IA usando **PyTorch, TensorFlow, etc.** diretamente na GPU da Azure.

Se precisar rodar isso em **Azure Machine Learning (AML)**, pode criar um **Compute Instance** com GPU e usar essa mesma imagem Docker.

Se precisar de mais ajuda, me avise! üöÄ

# Ja nao existe alguma IA com essa natureza?
Sim, **j√° existem IAs que cumprem parcialmente o trabalho de um advogado**, especialmente em **tarefas repetitivas, documentais e anal√≠ticas**. No entanto, **a atua√ß√£o completa de um advogado ainda n√£o pode ser totalmente substitu√≠da** por IA devido a fatores como interpreta√ß√£o jur√≠dica complexa, √©tica, empatia humana e decis√µes estrat√©gicas.

---

## ‚öñÔ∏è **√Åreas em que a IA j√° atua no Direito**

### ‚úÖ **Automa√ß√£o de Tarefas Jur√≠dicas Repetitivas**
- **Reda√ß√£o de contratos b√°sicos**
- **Revis√£o e an√°lise de documentos**
- **Extra√ß√£o de cl√°usulas** em grandes volumes contratuais
- **Pesquisa jur√≠dica automatizada**
- **Classifica√ß√£o de documentos legais**

### ‚úÖ **An√°lise de Jurisprud√™ncia e Precedentes**
- IAs conseguem analisar milhares de decis√µes judiciais para encontrar **padr√µes, argumentos e resultados esperados**.

### ‚úÖ **Chatbots Jur√≠dicos**
- Atendem clientes, esclarecem d√∫vidas legais simples e oferecem **orienta√ß√£o pr√©-jur√≠dica**.
- Ex: DoNotPay (EUA), Jusbot (Brasil).

### ‚úÖ **Predi√ß√£o de Decis√µes Judiciais**
- Algumas plataformas utilizam IA para prever **probabilidade de √™xito em a√ß√µes judiciais** com base em dados hist√≥ricos.

---

## ü§ñ **Exemplos Reais de IAs Jur√≠dicas**

| Nome | Fun√ß√£o | N√≠vel de automa√ß√£o |
|------|--------|--------------------|
| **DoNotPay** | Chatbot jur√≠dico que ajuda com multas, cancelamentos, pequenos processos | üü° Parcial |
| **ROSS Intelligence** (encerrado em 2021) | IA para pesquisa jur√≠dica com base em IBM Watson | üü° Parcial |
| **LawGeex** | Revis√£o autom√°tica de contratos com precis√£o compar√°vel √† de advogados humanos | üü¢ Alta |
| **Luminance** | An√°lise e auditoria de documentos jur√≠dicos com IA | üü¢ Alta |
| **Jusbot** (Brasil) | Chatbot de orienta√ß√£o jur√≠dica inicial | üü° Parcial |
| **ChatGPT/OpenAI + Plugins Jur√≠dicos** | Pode gerar peti√ß√µes, revisar contratos, responder d√∫vidas legais simples | üü° Parcial |

---

## üö´ **Limita√ß√µes da IA no Direito**

- ‚ùå **N√£o substitui o julgamento estrat√©gico e √©tico do advogado**
- ‚ùå **N√£o representa clientes judicialmente**
- ‚ùå **N√£o pode oferecer garantias legais** (problemas de responsabilidade e regula√ß√£o)
- ‚ùå **Dificuldade em interpretar nuances legais e contexto social**

---

## ‚öñÔ∏è **IA como Assistente, n√£o Substituto**

Hoje, a IA √© vista como uma **ferramenta de aumento de produtividade** no Direito:

> üß† *"Advogados que usam IA substituir√£o advogados que n√£o usam IA."*  
> ‚Äî Parafraseando uma vis√£o moderna da transforma√ß√£o digital no setor jur√≠dico

---

## üõ†Ô∏è **Quer testar?**

Voc√™ pode experimentar:
- **ChatGPT com Plugins Jur√≠dicos** (usando GPT-4)
- **Ferramentas como LawGeex, Luminance** (trials dispon√≠veis)
- **Criar seu pr√≥prio assistente jur√≠dico com Azure OpenAI + Prompt Engineering**

Se quiser, posso te ajudar a:
- Criar um **chatbot jur√≠dico com LLM**
- Escrever um **modelo de contrato com IA**
- Montar um **projeto de IA para automa√ß√£o legal**

Deseja seguir por alguma dessas op√ß√µes?

# Azure Container Instance and Azure Kubernet Service
Claro! Vamos abordar de forma clara e pr√°tica os dois servi√ßos citados: **Azure Kubernetes Service (AKS)** e **Azure Container Instances (ACI)**. Ambos s√£o solu√ß√µes para rodar cont√™ineres no Azure, mas com **n√≠veis diferentes de complexidade, controle e escalabilidade**.

---

## üîπ **1. Azure Container Instances (ACI)**

### ‚úÖ Ideal para:
- Executar **cont√™ineres simples e r√°pidos**, sem se preocupar com infraestrutura.
- Casos de uso **tempor√°rios** ou de **baixa escala**.
- Testes, tarefas autom√°ticas ou pequenas APIs.

### üß± Requisitos b√°sicos:
- Ter uma **imagem Docker** pronta (no Docker Hub, Azure Container Registry ou outro reposit√≥rio).
- Ter o **Azure CLI** instalado.

### üöÄ Como come√ßar:

#### 1. Login no Azure:
```bash
az login
```

#### 2. Criar um grupo de recursos:
```bash
az group create --name MeuGrupo --location eastus
```

#### 3. Criar uma inst√¢ncia de cont√™iner rodando uma imagem Docker:
```bash
az container create \
  --resource-group MeuGrupo \
  --name meucontainer \
  --image nginx \
  --cpu 1 \
  --memory 1 \
  --ports 80 \
  --dns-name-label meucontainerdns123 \
  --location eastus
```

#### 4. Verificar se est√° funcionando:
```bash
az container show --resource-group MeuGrupo --name meucontainer --query ipAddress.fqdn
```

Abra o endere√ßo no navegador e veja o NGINX rodando.

### ‚ö†Ô∏è Limita√ß√µes:
- **N√£o suporta GPU diretamente**.
- N√£o √© adequado para cargas de trabalho complexas ou escal√°veis.

---

## üî∑ **2. Azure Kubernetes Service (AKS)**

### ‚úÖ Ideal para:
- Aplica√ß√µes complexas em **escala**.
- Uso de m√∫ltiplos cont√™ineres, **balanceamento de carga**, **autoescalonamento**, **GPU**, etc.
- Ambientes de produ√ß√£o com **resili√™ncia e alta disponibilidade**.

### üß± Requisitos b√°sicos:
- Conhecimento b√°sico de **Kubernetes** (pods, deployments, services).
- Azure CLI e a extens√£o AKS:
```bash
az extension add --name aks
```
- Docker instalado (para criar imagens locais).

---

### üöÄ Como come√ßar com AKS:

#### 1. Criar grupo de recursos:
```bash
az group create --name MeuGrupoAKS --location eastus
```

#### 2. Criar um cluster AKS:
```bash
az aks create \
  --resource-group MeuGrupoAKS \
  --name MeuClusterAKS \
  --node-count 1 \
  --enable-addons monitoring \
  --generate-ssh-keys
```

#### 3. Conectar ao cluster:
```bash
az aks get-credentials --resource-group MeuGrupoAKS --name MeuClusterAKS
```

#### 4. Criar um app simples (por exemplo, NGINX):
```bash
kubectl create deployment nginx --image=nginx
kubectl expose deployment nginx --port=80 --type=LoadBalancer
```

#### 5. Obter o IP p√∫blico:
```bash
kubectl get services
```

Abra o IP no navegador.

---

### ‚öôÔ∏è GPU no AKS:
Se desejar rodar modelos com GPU (como no Ollama), crie **n√≥s com GPU**:
```bash
az aks nodepool add \
  --resource-group MeuGrupoAKS \
  --cluster-name MeuClusterAKS \
  --name gpupool \
  --node-count 1 \
  --node-vm-size Standard_NC6 \
  --enable-node-public-ip \
  --aks-custom-headers UseGPUDedicatedVHD=true
```

Voc√™ pode ent√£o agendar workloads para esse pool com `nodeSelector`.

---

## üÜö Comparativo R√°pido

| Recurso | ACI | AKS |
|--------|-----|-----|
| Setup | Muito simples | Mais complexo |
| Escalabilidade | Limitada | Altamente escal√°vel |
| Suporte a GPU | ‚ùå N√£o | ‚úÖ Sim |
| Ideal para | Testes, jobs simples | Produ√ß√£o, cargas complexas |
| Pre√ßo | Paga por segundo de uso | Cobra por VM (mesmo ociosa) |
| Gerenciamento | Zero infra | Voc√™ gerencia o cluster |

---

## üîö Conclus√£o

- **Comece com o ACI** se quiser testar rapidamente seu cont√™iner.
- **Use o AKS** se estiver construindo uma **infraestrutura robusta para produ√ß√£o**, especialmente com **GPU** para LLMs.

---

Se quiser, posso te fornecer:
- Um **template YAML para AKS** com Ollama rodando.
- Um **workflow CI/CD do GitHub Actions** para publicar imagens no Azure e deploy autom√°tico.

√â s√≥ pedir! üöÄ
